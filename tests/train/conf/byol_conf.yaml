env:
  seed: 1337
  numpy_seed: 1337
  jax_seed: 1337
  epochs: 100
  accum_steps: 1
  save_checkpoint:
    params:
      ckpt_dir: "outs/checkpoints/"
      keep: 1
      overwrite: True
      keep_every_n_steps: 300
  restore_checkpoint:
    params: {}
  half_precision: False
  dynamic_scale:
    params: {}

trainer:
  name: SSLTrainer

model:
  name: SSLModel
  branches:
    0:
      name: OnlineBranch
      params:
        body:
          name: ResNet
          params:
            stage_sizes: [3, 4, 6, 3]
            block_cls_name: "BottleneckResNetBlock"
            num_classes: False
        head:
          name: MLP
          params:
            layer_dims: [4096, 256]
            dropout_prob: 0.0
            batch_norm: False
            batch_norm_params:
                decay_rate: 0.9
                epsilon: 1e-5
            activation_name: "relu"
        pred:
          name: MLP
          params:
            layer_dims: [4096, 256]
            dropout_prob: 0.0
            batch_norm: False
            batch_norm_params:
                decay_rate: 0.9
                epsilon: 1e-5
            activation_name: "relu"

    1:
      name: TargetBranch
      params:
        body:
          name: ResNet
          params:
            stage_sizes: [3, 4, 6, 3]
            block_cls_name: "BottleneckResNetBlock"
            num_classes: False
        head:
          name: MLP
          params:
            layer_dims: [4096, 256]
            dropout_prob: 0.0
            batch_norm: True
            batch_norm_params:
              use_running_average: True
              momentum: 0.9
              epsilon: 1e-5
            activation_name: "relu"


loss: byol_regression_loss

optimizers:
  branches:
    0:
      name: lars
      params:
        # TODO: check that this should be momentum (comes from deepmind's \beta)
        momentum: 0.9
        trust_coefficient: 1e-3
        weight_decay: 1.5e-6
        weight_decay_mask: True
        trust_ratio_mask: True

schedulers:
  branches:
    0:
      name: BYOL
      params:
        # note that learning rate scales w/ number of epochs see deepmind implementation
        base_learning_rate: 0.45
        warmup_steps: 1000
        batch_size: 4096
        # epochs * train_images_per_epoch // batch_size
        # TODO: for now this is a random number
        total_steps: 100000

post_process:
  funcs:
    0:
      name: ema
      params:
        online_branch_name: branch_0
        target_branch_name: branch_1
        tau: 0.9

meter:
  name: SSLMeter

pipelines:
  branches:
    0:
      name: BYOLOnlinePipeline
      params: {}
    1:
      name: BYOLTargetPipeline
      params: {}

dataloader:
  name: cifar10
  params:
    batch_size: 4096
    flatten: False
    input_shape: (32,32,3)
